{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8398aabf-5770-40ce-a2ea-ee942b1f609c",
   "metadata": {},
   "source": [
    "This notebook contains the postprocessing of the results and visualization to compare with the results obtained of the semantic segmentation task on the toy data set in the corresponding paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e67004-a13d-4309-801f-97f1d8f46b30",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utility functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62178ff9-4e0b-4aec-a5fc-9aec5d9611f8",
   "metadata": {},
   "source": [
    "This section contains all auxilary functions required to compute the mean and the standard deviation of the metrics. It can be ignored except if new comparisons need to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d7e0d-0ad0-46a5-bc96-8fba773f10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522f05b-ebc6-4430-94b5-3b7b98b3b30d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute Mean/Standard deviation/Maximum/Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff65194-6f0b-4265-8778-aeee2cd7c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_max_min_std_method(directory_results, method, seeds_list, metrics, directory_postprocessed_results, epochs):\n",
    "    \"\"\"Compute the mean, maximum, minimum, and standard deviation for a method over the different seeds for each metric provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory_results : str\n",
    "        String denoting the path to the directory where the results are stored.\n",
    "    method : str\n",
    "        String denoting the name of the method.\n",
    "    seeds_list : list[int]\n",
    "        List of integers denoting the pseudo-random seeds used during the experiments.\n",
    "    metrics : list[str]\n",
    "        List of strings denoting which metrics are considered. The metrics that are supported are: tra_sat_ratio, val_sat_ratio, tra_dice, \n",
    "        and val_dice. A numpy array of zeros will be stored if a different metric is passed to this function. It will be printed when an \n",
    "        unsupported metric is passed to this function.\n",
    "    directory_postprocessed_results : str\n",
    "        String denoting the path to the directory where the mean, maximum, minimum, and standard deviation arrays are stored.\n",
    "    epochs : int\n",
    "        Integer denoting the number of epochs that were done during training.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \n",
    "    \"\"\"\n",
    "    for current_metric in metrics:\n",
    "        \n",
    "        temp_mean_array = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        temp_max_array = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        temp_min_array = np.ones([epochs, 1], dtype=np.float32)\n",
    "        temp_std_array = np.zeros([epochs, len(seeds_list)], dtype=np.float32)\n",
    "        \n",
    "        if current_metric == 'tra_sat_ratio' or current_metric == 'val_sat_ratio':\n",
    "            for current_seed_index in range(0, len(seeds_list)):\n",
    "                current_value = np.reshape(np.load(directory_results + method + str(seeds_list[current_seed_index]) + '/' + current_metric + '.npy'), [epochs, 1])\n",
    "\n",
    "                temp_mean_array = temp_mean_array + current_value\n",
    "                temp_max_array = np.maximum(temp_max_array, current_value)\n",
    "                temp_min_array = np.minimum(temp_min_array, current_value)\n",
    "                temp_std_array[:, current_seed_index] = np.reshape(current_value, [epochs,])\n",
    "\n",
    "            temp_mean_array = temp_mean_array / len(seeds_list)\n",
    "            temp_std_array = np.reshape(np.std(temp_std_array, axis=1), [epochs, 1])\n",
    "            \n",
    "        elif current_metric == 'tra_dice' or current_metric == 'val_dice':\n",
    "            for current_seed_index in range(0, len(seeds_list)):\n",
    "                current_value = np.reshape(np.mean(np.load(directory_results + method + str(seeds_list[current_seed_index]) + '/' + current_metric + '.npy')[:, :, -1], axis=1), [epochs, 1])\n",
    "                \n",
    "                temp_mean_array = temp_mean_array + current_value\n",
    "                temp_max_array = np.maximum(temp_max_array, current_value)\n",
    "                temp_min_array = np.minimum(temp_min_array, current_value)\n",
    "                temp_std_array[:, current_seed_index] = np.reshape(current_value, [epochs,])\n",
    "\n",
    "            temp_mean_array = temp_mean_array / len(seeds_list)\n",
    "            temp_std_array = np.reshape(np.std(temp_std_array, axis=1), [epochs, 1])\n",
    "        else:\n",
    "            print('Metric: ' + str(current_metric) + ' is not supported. See the documentation to see which metrics are supported.')\n",
    "                \n",
    "        \n",
    "        # save the results\n",
    "        np.save(file=directory_postprocessed_results + method + current_metric + '_mean', arr=temp_mean_array)\n",
    "        np.save(file=directory_postprocessed_results + method + current_metric + '_max', arr=temp_max_array)\n",
    "        np.save(file=directory_postprocessed_results + method + current_metric + '_min', arr=temp_min_array)\n",
    "        np.save(file=directory_postprocessed_results + method + current_metric + '_std', arr=temp_std_array)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70642f-c8de-4629-8d7e-f2578394a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_satisfaction_ratio(directory_results, method, seeds_list, epochs):\n",
    "    \"\"\" Compute the satisfaction ratio for the train and validation set from the number of constraints and the number of satisfied constraints.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory_results : str\n",
    "        String denoting the path to the directory where the results for each method is stored.\n",
    "    method : str\n",
    "        String denoting the method that was used during training.\n",
    "    seeds_list : list[int]\n",
    "        List of integers denoting the pseudo-random seeds used in the experiments.\n",
    "    epochs : int\n",
    "        Integer denoting the number of epochs that were done during training.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(0, len(seeds_list)):\n",
    "        temp_tra_con = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        temp_tra_sat_con = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        temp_val_con = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        temp_val_sat_con = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        \n",
    "        temp_tra_sat_ratio = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        temp_val_sat_ratio = np.zeros([epochs, 1], dtype=np.float32)\n",
    "        \n",
    "        temp_tra_con = np.reshape(np.sum(np.reshape(np.load(directory_results + method + str(seeds_list[i]) + '/' + 'tra_number_con' + '.npy'), [epochs, -1]), axis=1), [epochs, 1])\n",
    "        temp_tra_sat_con = np.reshape(np.sum(np.reshape(np.load(directory_results + method + str(seeds_list[i]) + '/' + 'tra_sat_number_con' + '.npy'), [epochs, -1]), axis=1), [epochs, 1])\n",
    "        temp_val_con = np.reshape(np.sum(np.reshape(np.load(directory_results + method + str(seeds_list[i]) + '/' + 'val_number_con' + '.npy'), [epochs, -1]), axis=1), [epochs, 1])\n",
    "        temp_val_sat_con = np.reshape(np.sum(np.reshape(np.load(directory_results + method + str(seeds_list[i]) + '/' + 'val_sat_number_con' + '.npy'), [epochs, -1]), axis=1), [epochs, 1])\n",
    "        \n",
    "        temp_tra_sat_ratio = temp_tra_sat_con / temp_tra_con\n",
    "        temp_val_sat_ratio = temp_val_sat_con / temp_val_con\n",
    "        \n",
    "        np.save(file=directory_results + method + str(seeds_list[i]) + '/' + 'tra_sat_ratio', arr=temp_tra_sat_ratio)\n",
    "        np.save(file=directory_results + method + str(seeds_list[i]) + '/' + 'val_sat_ratio', arr=temp_val_sat_ratio)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbe807-0aff-4232-a737-e861ed3ced54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_epoch_cggd(directory_results, method, seeds_list, tra=True):\n",
    "    \"\"\" Compute the best epoch for cggd. This is the epoch with the highest satisfaction ratio because technically speaking we cannot use the labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory_results : str\n",
    "        String denoting the path to the directory where the results for each method is stored.\n",
    "    method : str\n",
    "        String denoting the method that was used during training.\n",
    "    seeds_list : list[int]\n",
    "        List of integers denoting the pseudo-random seeds used in the experiments.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    if tra:\n",
    "        for i in range(0, len(seeds_list)):\n",
    "            current_tra_sat_ratio = np.load(directory_results + method + str(seeds_list[i]) + '/' + 'tra_sat_ratio.npy')\n",
    "            current_index = np.reshape(np.argmax(current_tra_sat_ratio), [1,])\n",
    "\n",
    "            np.save(file=directory_results + method + str(seeds_list[i]) + '/' + 'best_epoch_max_tra_sat', arr=current_index)\n",
    "    else:\n",
    "        for i in range(0, len(seeds_list)):\n",
    "            current_tra_sat_ratio = np.load(directory_results + method + str(seeds_list[i]) + '/' + 'val_sat_ratio.npy')\n",
    "            current_index = np.reshape(np.argmax(current_tra_sat_ratio), [1,])\n",
    "\n",
    "            np.save(file=directory_results + method + str(seeds_list[i]) + '/' + 'best_epoch_max_tra_sat', arr=current_index)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3c5f9-37fe-4897-8829-36506e57a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_best_epoch_txt(directory_results, methods, seeds_list):\n",
    "    \"\"\"Convert the txt to a .npy file that contains the best epoch.\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory_results : str\n",
    "        String denoting the path to the directory where the results for each method is stored.\n",
    "    method : str\n",
    "        String denoting the method that was used during training.\n",
    "    seeds_list : list[int]\n",
    "        List of integers denoting the pseudo-random seeds used in the experiments.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    for current_method in methods:\n",
    "        for i in range(0, len(seeds_list)):\n",
    "            with open(directory_results + current_method + str(seeds_list[i]) + '/best_epoch.txt') as handle:\n",
    "                current_best_epoch = handle.readlines()[0]\n",
    "            np.save(directory_results + current_method + str(seeds_list[i]) + '/' + 'best_epoch.npy', arr=np.reshape(np.asarray(current_best_epoch), [1,]))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce8698-d489-4f6b-af26-ee751ba9bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe_mean_std(directory_results, directory_postprocessed_results, methods, metrics, seeds_list, epochs, custom_epoch=True, custom_epoch_base=False):\n",
    "    \"\"\"Compute the mean and standard deviation of the best epoch for the different methods and the different metrics.\n",
    "    \"\"\"\n",
    "    result_array = np.zeros([len(methods), 2*len(metrics)], dtype=np.float32)\n",
    "    \n",
    "    for i in range(0, len(methods)):\n",
    "        if methods[i] == 'cggd_size_centroid_' or methods[i] == 'cggd_box_prior_box_size_':\n",
    "            if custom_epoch:\n",
    "                for j in range(0, len(metrics)):\n",
    "                    if metrics[j] == 'tra_dice' or metrics[j] == 'val_dice':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.mean(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy')[:, :, -1], axis=1), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch_max_tra_sat.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    elif metrics[j] == 'tra_sat_ratio' or metrics[j] == 'val_sat_ratio':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy'), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch_max_tra_sat.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    else:\n",
    "                        print('Metric ' + metrics[j] + ' is not supported.')\n",
    "            else:\n",
    "                for j in range(0, len(metrics)):\n",
    "                    if metrics[j] == 'tra_dice' or metrics[j] == 'val_dice':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.mean(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy')[:, :, -1], axis=1), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    elif metrics[j] == 'tra_sat_ratio' or metrics[j] == 'val_sat_ratio':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy'), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    else:\n",
    "                        print('Metric ' + metrics[j] + ' is not supported.')\n",
    "        else:\n",
    "            if custom_epoch_base:\n",
    "                for j in range(0, len(metrics)):\n",
    "                    if metrics[j] == 'tra_dice' or metrics[j] == 'val_dice':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.mean(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy')[:, :, -1], axis=1), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch_max_tra_sat.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    elif metrics[j] == 'tra_sat_ratio' or metrics[j] == 'val_sat_ratio':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy'), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch_max_tra_sat.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    else:\n",
    "                        print('Metric ' + metrics[j] + ' is not supported.')\n",
    "            else:\n",
    "                for j in range(0, len(metrics)):\n",
    "                    if metrics[j] == 'tra_dice' or metrics[j] == 'val_dice':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.mean(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy')[:, :, -1], axis=1), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    elif metrics[j] == 'tra_sat_ratio' or metrics[j] == 'val_sat_ratio':\n",
    "                        temp_array = np.zeros([len(seeds_list),], dtype=np.float32)\n",
    "                        for k in range(0, len(seeds_list)):\n",
    "                            current_value = np.reshape(np.load(directory_results + methods[i] + str(seeds_list[k]) + '/' + metrics[j] + '.npy'), [epochs,])\n",
    "                            current_best_epoch = np.load(directory_results + methods[i] + str(seeds_list[k]) + '/best_epoch.npy')\n",
    "\n",
    "                            temp_array[k] = current_value[int(current_best_epoch)]\n",
    "\n",
    "                        result_array[i, 2*j] = np.mean(temp_array)\n",
    "                        result_array[i, 2*j+1] = np.std(temp_array)\n",
    "                    else:\n",
    "                        print('Metric ' + metrics[j] + ' is not supported.')\n",
    "    \n",
    "    header_list = []\n",
    "    for i in metrics:\n",
    "        header_list.append('mean ' + i)\n",
    "        header_list.append('std ' + i)\n",
    "        \n",
    "    method_legend = {'fs_': 'Baseline', 'cggd_box_prior_box_size_': 'CGGD', 'logbarrier_box_prior_box_size_': 'Logbarrier', 'penalty_box_prior_box_size_': 'Penalty', 'cggd_size_centroid_': 'CGGD', 'logbarrier_size_centroid_': 'Logbarrier', 'penalty_size_centroid_': 'Penalty'}\n",
    "    \n",
    "    df_result = pd.DataFrame(result_array, columns=header_list, index=[method_legend[k] for k in methods])\n",
    "    np.save(file=directory_postprocessed_results + 'mean_and_standard_deviation.npy', arr=result_array)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bdabb-ef33-4d2e-9f29-aae835c71aa9",
   "metadata": {},
   "source": [
    "## Plot Mean/Standard deviation/Minimum/Maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de426fd7-5473-4c10-a8f1-a908eb2a3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(directory_results, directory_postprocessed_results, methods, seeds_list, metrics, epochs):\n",
    "    font = FontProperties()\n",
    "    font.set_family('serif')\n",
    "    mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "    mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "    mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "    mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'\n",
    "    colors_list = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "    metric_legend = {'tra_dice': 'dice loss train', 'val_dice': 'dice loss validation', 'tra_sat_ratio': 'satisfaction ratio train', 'val_sat_ratio': 'satisfaction ratio validation'}\n",
    "    method_legend = {'fs_': 'Baseline', 'cggd_box_prior_box_size_': 'CGGD', 'logbarrier_box_prior_box_size_': 'Logbarrier', 'penalty_box_prior_box_size_': 'Penalty', 'cggd_size_centroid_': 'CGGD', 'logbarrier_size_centroid_': 'Logbarrier', 'penalty_size_centroid_': 'Penalty'}\n",
    "    for i in range(0, len(metrics)):\n",
    "        values_array = np.zeros([epochs, len(methods)], dtype=np.float32)\n",
    "        for j in range(0, len(methods)):\n",
    "            values_array[:, j] = np.reshape(np.load(directory_postprocessed_results + methods[j] + metrics[i] + '_mean.npy'), [epochs,])\n",
    "        \n",
    "        df_values = pd.DataFrame(values_array, index=range(1, epochs+1))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "        plt.title('Mean ' + metric_legend[metrics[i]])\n",
    "        plt.axhline(y=0, color='black', linestyle='-')\n",
    "        plt.axhline(y=1, color='black', linestyle='--')\n",
    "        plt.xlim(0, epochs)\n",
    "        plt.xlabel('Epoch')\n",
    "        df_values.columns = [method_legend[k] for k in methods]\n",
    "        df_values.plot(ax=ax, color=colors_list)\n",
    "        plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849def76-8461-43d8-81f6-b745986b3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_std(directory_results, directory_postprocessed_results, methods, seeds_list, metrics, epochs):\n",
    "    font = FontProperties()\n",
    "    font.set_family('serif')\n",
    "    mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "    mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "    mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "    mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'\n",
    "    colors_list = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "    metric_legend = {'tra_dice': 'dice loss train', 'val_dice': 'dice loss validation', 'tra_sat_ratio': 'satisfaction ratio train', 'val_sat_ratio': 'satisfaction ratio validation'}\n",
    "    method_legend = {'fs_': 'Baseline', 'cggd_box_prior_box_size_': 'CGGD', 'logbarrier_box_prior_box_size_': 'Logbarrier', 'penalty_box_prior_box_size_': 'Penalty', 'cggd_size_centroid_': 'CGGD', 'logbarrier_size_centroid_': 'Logbarrier', 'penalty_size_centroid_': 'Penalty'}\n",
    "    for i in range(0, len(metrics)):\n",
    "        values_array = np.zeros([epochs, len(methods)], dtype=np.float32)\n",
    "        for j in range(0, len(methods)):\n",
    "            values_array[:, j] = np.reshape(np.load(directory_postprocessed_results + methods[j] + metrics[i] + '_std.npy'), [epochs,])\n",
    "        \n",
    "        df_values = pd.DataFrame(values_array, index=range(1, epochs+1))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "        plt.title('Standard deviation ' + metric_legend[metrics[i]])\n",
    "        plt.axhline(y=0, color='black', linestyle='-')\n",
    "        plt.xlim(0, epochs)\n",
    "        plt.xlabel('Epoch')\n",
    "        df_values.columns = [method_legend[k] for k in methods]\n",
    "        df_values.plot(ax=ax, color=colors_list)\n",
    "        plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0626cac-92a3-4177-99ba-740ee5b020c9",
   "metadata": {},
   "source": [
    "## Plot ratio between train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9db32a-404f-434f-997c-6bbd07ee0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_ratio(directory_results, directory_postprocessed_results, methods, seeds_list, metrics, epochs):\n",
    "    font = FontProperties()\n",
    "    font.set_family('serif')\n",
    "    mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "    mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "    mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "    mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'\n",
    "    colors_list = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "    metric_legend = {'tra_dice': 'dice loss train', 'val_dice': 'dice loss validation', 'tra_sat_ratio': 'satisfaction ratio train', 'val_sat_ratio': 'satisfaction ratio validation', 'dice': 'Dice loss', 'sat_ratio': 'Satisfaction ratio'}\n",
    "    method_legend = {'fs_': 'Baseline', 'cggd_box_prior_box_size_': 'CGGD', 'logbarrier_box_prior_box_size_': 'Logbarrier', 'penalty_box_prior_box_size_': 'Penalty', 'cggd_size_centroid_': 'CGGD', 'logbarrier_size_centroid_': 'Logbarrier', 'penalty_size_centroid_': 'Penalty'}\n",
    "    for i in range(0, len(metrics)):\n",
    "        values_train_array = np.zeros([epochs, len(methods)], dtype=np.float32)\n",
    "        values_val_array = np.zeros([epochs, len(methods)], dtype=np.float32)\n",
    "        for j in range(0, len(methods)):\n",
    "            values_train_array[:, j] = np.reshape(np.load(directory_postprocessed_results + methods[j] + 'tra_' +  metrics[i] + '_mean.npy'), [epochs,])\n",
    "            values_val_array[:, j] = np.reshape(np.load(directory_postprocessed_results + methods[j] + 'val_' +  metrics[i] + '_mean.npy'), [epochs,])\n",
    "        \n",
    "        df_values = pd.DataFrame(values_train_array / values_val_array, index=range(1, epochs+1))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "        plt.title('Mean ratio between train and validation of ' + metric_legend[metrics[i]])\n",
    "        plt.axhline(y=0, color='black', linestyle='-')\n",
    "        plt.axhline(y=1, color='black', linestyle='--')\n",
    "        plt.xlim(0, epochs)\n",
    "        plt.ylim(0, 2)\n",
    "        plt.xlabel('Epoch')\n",
    "        df_values.columns = [method_legend[k] for k in methods]\n",
    "        df_values.plot(ax=ax, color=colors_list)\n",
    "        plt.show()\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe56c1a-37f3-455b-ba67-56bf7658c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_std_ratio(directory_results, directory_postprocessed_results, methods, seeds_list, metrics, epochs):\n",
    "    font = FontProperties()\n",
    "    font.set_family('serif')\n",
    "    mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "    mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "    mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "    mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'\n",
    "    colors_list = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "    metric_legend = {'tra_dice': 'dice loss train', 'val_dice': 'dice loss validation', 'tra_sat_ratio': 'satisfaction ratio train', 'val_sat_ratio': 'satisfaction ratio validation', 'dice': 'Dice loss', 'sat_ratio': 'Satisfaction ratio'}\n",
    "    method_legend = {'fs_': 'Baseline', 'cggd_box_prior_box_size_': 'CGGD', 'logbarrier_box_prior_box_size_': 'Logbarrier', 'penalty_box_prior_box_size_': 'Penalty', 'cggd_size_centroid_': 'CGGD', 'logbarrier_size_centroid_': 'Logbarrier', 'penalty_size_centroid_': 'Penalty'}\n",
    "    for i in range(0, len(metrics)):\n",
    "        values_train_array = np.zeros([epochs, len(methods)], dtype=np.float32)\n",
    "        values_val_array = np.zeros([epochs, len(methods)], dtype=np.float32)\n",
    "        for j in range(0, len(methods)):\n",
    "            values_train_array[:, j] = np.reshape(np.load(directory_postprocessed_results + methods[j] + 'tra_' +  metrics[i] + '_std.npy'), [epochs,])\n",
    "            values_val_array[:, j] = np.reshape(np.load(directory_postprocessed_results + methods[j] + 'val_' +  metrics[i] + '_std.npy'), [epochs,])\n",
    "        \n",
    "        df_values = pd.DataFrame(values_train_array / values_val_array, index=range(1, epochs+1))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "        plt.title('Standard deviation ratio between train and validation of ' + metric_legend[metrics[i]])\n",
    "        plt.axhline(y=0, color='black', linestyle='-')\n",
    "        plt.xlim(0, epochs)\n",
    "        plt.ylim(0, 2)\n",
    "        plt.xlabel('Epoch')\n",
    "        df_values.columns = [method_legend[k] for k in methods]\n",
    "        df_values.plot(ax=ax, color=colors_list)\n",
    "        plt.show()\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864409f-a21d-42d4-89a0-0660a92daed4",
   "metadata": {},
   "source": [
    "## Compare convergence speed CGGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a84df-808b-42cb-9036-09a0812825ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_speed_mean(directory_postprocessed_results, directory_postprocessed_results_50, directory_postprocessed_results_10, metrics, seeds_list, epochs, epochs_50=None, epochs_10=None, train=True, val=True):\n",
    "    font = FontProperties()\n",
    "    font.set_family('serif')\n",
    "    mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "    mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "    mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "    mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'\n",
    "    colors_list = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "    metric_legend = {'tra_dice': 'dice loss train', 'val_dice': 'dice loss validation', 'tra_sat_ratio': 'satisfaction ratio train', 'val_sat_ratio': 'satisfaction ratio validation', 'dice': 'Dice loss', 'sat_ratio': 'Satisfaction ratio'}\n",
    "    method_legend = {'fs_': 'Baseline', 'cggd_box_prior_box_size_': 'CGGD', 'logbarrier_box_prior_box_size_': 'Logbarrier', 'penalty_box_prior_box_size_': 'Penalty', 'cggd_size_centroid_': 'CGGD', 'logbarrier_size_centroid_': 'Logbarrier', 'penalty_size_centroid_': 'Penalty'}\n",
    "    size_legend = {'Full': 'Full', '50%': '50%', '10%': '10%'}\n",
    "    sizes = ['Full', '50%', '10%']\n",
    "    \n",
    "    if epochs_50 is None:\n",
    "        epochs_50 = epochs\n",
    "    if epochs_10 is None:\n",
    "        epochs_10 = epochs\n",
    "    \n",
    "    for i in range(0, len(metrics)):\n",
    "        if train:\n",
    "            values_array_full = np.zeros([epochs, ], dtype=np.float32)\n",
    "            values_array_50 = np.zeros([int(epochs_50 / 2), ], dtype=np.float32)\n",
    "            values_array_10 = np.zeros([int(epochs_10 / 10), ], dtype=np.float32)\n",
    "\n",
    "            values_full = np.reshape(np.load(directory_postprocessed_results + 'cggd_size_centroid_' + 'tra_' +  metrics[i] + '_mean.npy'), [epochs,])\n",
    "            values_50 = np.reshape(np.load(directory_postprocessed_results_50 + 'cggd_size_centroid_' + 'tra_' +  metrics[i] + '_mean.npy'), [epochs_50,])\n",
    "            values_10 = np.reshape(np.load(directory_postprocessed_results_10 + 'cggd_size_centroid_' + 'tra_' +  metrics[i] + '_mean.npy'), [epochs_10,])\n",
    "\n",
    "            for j in range(0, int(epochs_50 / 2)):\n",
    "                values_array_50[j] = values_50[2*j]\n",
    "            for j in range(0, int(epochs_10 / 10)):\n",
    "                values_array_10[j] = values_10[10*j]\n",
    "\n",
    "            values_dict = {}\n",
    "            values_dict['Full'] = values_full\n",
    "            values_dict['50%'] = values_array_50\n",
    "            values_dict['10%'] = values_array_10\n",
    "            \n",
    "            df_values = pd.DataFrame.from_dict(values_dict, orient='index').transpose()\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "            plt.title('Mean of ' + metric_legend[metrics[i]] + ' train for CGGD with different amounts of patients.')\n",
    "            plt.axhline(y=0, color='black', linestyle='-')\n",
    "            plt.axhline(y=1, color='black', linestyle='--')\n",
    "            plt.xlim(0, max(epochs, int(epochs_50 / 2), int(epochs_10 / 10)))\n",
    "            df_values.columns = [size_legend[k] for k in sizes]\n",
    "            df_values.plot(ax=ax, color=colors_list)\n",
    "            plt.show()\n",
    "            \n",
    "        if val:\n",
    "            values_array_full = np.zeros([epochs, ], dtype=np.float32)\n",
    "            values_array_50 = np.zeros([int(epochs_50 / 2), ], dtype=np.float32)\n",
    "            values_array_10 = np.zeros([int(epochs_10 / 10), ], dtype=np.float32)\n",
    "\n",
    "            values_full = np.reshape(np.load(directory_postprocessed_results + 'cggd_size_centroid_' + 'val_' +  metrics[i] + '_mean.npy'), [epochs,])\n",
    "            values_50 = np.reshape(np.load(directory_postprocessed_results_50 + 'cggd_size_centroid_' + 'val_' +  metrics[i] + '_mean.npy'), [epochs_50,])\n",
    "            values_10 = np.reshape(np.load(directory_postprocessed_results_10 + 'cggd_size_centroid_' + 'val_' +  metrics[i] + '_mean.npy'), [epochs_10,])\n",
    "\n",
    "            for j in range(0, int(epochs_50 / 2)):\n",
    "                values_array_50[j] = values_50[2*j]\n",
    "            for j in range(0, int(epochs_10 / 10)):\n",
    "                values_array_10[j] = values_10[10*j]\n",
    "\n",
    "            values_dict = {}\n",
    "            values_dict['Full'] = values_full\n",
    "            values_dict['50%'] = values_array_50\n",
    "            values_dict['10%'] = values_array_10\n",
    "            \n",
    "            df_values = pd.DataFrame.from_dict(values_dict, orient='index').transpose()\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "            plt.title('Mean of ' + metric_legend[metrics[i]] + ' validation for CGGD with different amounts of patients.')\n",
    "            plt.axhline(y=0, color='black', linestyle='-')\n",
    "            plt.axhline(y=1, color='black', linestyle='--')\n",
    "            plt.xlim(0, max(epochs, int(epochs_50 / 2), int(epochs_10 / 10)))\n",
    "            df_values.columns = [size_legend[k] for k in sizes]\n",
    "            df_values.plot(ax=ax, color=colors_list)\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce5ddb-e199-4d7d-b5ab-70bf16dd7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_speed_std(directory_postprocessed_results, directory_postprocessed_results_50, directory_postprocessed_results_10, metrics, seeds_list, epochs, epochs_50=None, epochs_10=None, train=True, val=True):\n",
    "    font = FontProperties()\n",
    "    font.set_family('serif')\n",
    "    mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "    mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "    mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "    mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'\n",
    "    colors_list = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "    metric_legend = {'tra_dice': 'dice loss train', 'val_dice': 'dice loss validation', 'tra_sat_ratio': 'satisfaction ratio train', 'val_sat_ratio': 'satisfaction ratio validation', 'dice': 'Dice loss', 'sat_ratio': 'Satisfaction ratio'}\n",
    "    method_legend = {'fs_': 'Baseline', 'cggd_box_prior_box_size_': 'CGGD', 'logbarrier_box_prior_box_size_': 'Logbarrier', 'penalty_box_prior_box_size_': 'Penalty', 'cggd_size_centroid_': 'CGGD', 'logbarrier_size_centroid_': 'Logbarrier', 'penalty_size_centroid_': 'Penalty'}\n",
    "    size_legend = {'Full': 'Full', '50%': '50%', '10%': '10%'}\n",
    "    sizes = ['Full', '50%', '10%']\n",
    "    \n",
    "    if epochs_50 is None:\n",
    "        epochs_50 = epochs\n",
    "    if epochs_10 is None:\n",
    "        epochs_10 = epochs\n",
    "    \n",
    "    for i in range(0, len(metrics)):\n",
    "        if train:\n",
    "            values_array_full = np.zeros([epochs, ], dtype=np.float32)\n",
    "            values_array_50 = np.zeros([int(epochs_50 / 2), ], dtype=np.float32)\n",
    "            values_array_10 = np.zeros([int(epochs_10 / 10), ], dtype=np.float32)\n",
    "\n",
    "            values_full = np.reshape(np.load(directory_postprocessed_results + 'cggd_size_centroid_' + 'tra_' +  metrics[i] + '_std.npy'), [epochs,])\n",
    "            values_50 = np.reshape(np.load(directory_postprocessed_results_50 + 'cggd_size_centroid_' + 'tra_' +  metrics[i] + '_std.npy'), [epochs_50,])\n",
    "            values_10 = np.reshape(np.load(directory_postprocessed_results_10 + 'cggd_size_centroid_' + 'tra_' +  metrics[i] + '_std.npy'), [epochs_10,])\n",
    "\n",
    "            for j in range(0, int(epochs_50 / 2)):\n",
    "                values_array_50[j] = values_50[2*j]\n",
    "            for j in range(0, int(epochs_10 / 10)):\n",
    "                values_array_10[j] = values_10[10*j]\n",
    "\n",
    "            values_dict = {}\n",
    "            values_dict['Full'] = values_full\n",
    "            values_dict['50%'] = values_array_50\n",
    "            values_dict['10%'] = values_array_10\n",
    "            \n",
    "            df_values = pd.DataFrame.from_dict(values_dict, orient='index').transpose()\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "            plt.title('Standard deviation of ' + metric_legend[metrics[i]] + ' train for CGGD with different amounts of patients.')\n",
    "            plt.axhline(y=0, color='black', linestyle='-')\n",
    "            plt.axhline(y=1, color='black', linestyle='--')\n",
    "            plt.xlim(0, max(epochs, int(epochs_50 / 2), int(epochs_10 / 10)))\n",
    "            df_values.columns = [size_legend[k] for k in sizes]\n",
    "            df_values.plot(ax=ax, color=colors_list)\n",
    "            plt.show()\n",
    "            \n",
    "        if val:\n",
    "            values_array_full = np.zeros([epochs, ], dtype=np.float32)\n",
    "            values_array_50 = np.zeros([int(epochs_50 / 2), ], dtype=np.float32)\n",
    "            values_array_10 = np.zeros([int(epochs_10 / 10), ], dtype=np.float32)\n",
    "\n",
    "            values_full = np.reshape(np.load(directory_postprocessed_results + 'cggd_size_centroid_' + 'val_' +  metrics[i] + '_std.npy'), [epochs,])\n",
    "            values_50 = np.reshape(np.load(directory_postprocessed_results_50 + 'cggd_size_centroid_' + 'val_' +  metrics[i] + '_std.npy'), [epochs_50,])\n",
    "            values_10 = np.reshape(np.load(directory_postprocessed_results_10 + 'cggd_size_centroid_' + 'val_' +  metrics[i] + '_std.npy'), [epochs_10,])\n",
    "\n",
    "            for j in range(0, int(epochs_50 / 2)):\n",
    "                values_array_50[j] = values_50[2*j]\n",
    "            for j in range(0, int(epochs_10 / 10)):\n",
    "                values_array_10[j] = values_10[10*j]\n",
    "\n",
    "            values_dict = {}\n",
    "            values_dict['Full'] = values_full\n",
    "            values_dict['50%'] = values_array_50\n",
    "            values_dict['10%'] = values_array_10\n",
    "            \n",
    "            df_values = pd.DataFrame.from_dict(values_dict, orient='index').transpose()\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "            plt.title('Standard deviation of ' + metric_legend[metrics[i]] + ' validation for CGGD with different amounts of patients.')\n",
    "            plt.axhline(y=0, color='black', linestyle='-')\n",
    "            plt.axhline(y=1, color='black', linestyle='--')\n",
    "            plt.xlim(0, max(epochs, int(epochs_50 / 2), int(epochs_10 / 10)))\n",
    "            df_values.columns = [size_legend[k] for k in sizes]\n",
    "            df_values.plot(ax=ax, color=colors_list)\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f54fa2-a6c5-43dd-b776-9db51bf4cfd8",
   "metadata": {},
   "source": [
    "# Compute Mean/Standard deviation/Minimum/Maximum and best epoch CGGD\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2f2b8-98cb-4c75-99a9-4f792b45fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory results data set\n",
    "directory_results = './results/toy/'\n",
    "directory_results_10 = './results/toy_10/'\n",
    "directory_results_50 = './results/toy_50/'\n",
    "\n",
    "# The following methods are tested\n",
    "full_sup = 'fs_'\n",
    "\n",
    "cggd_size_centroid = 'cggd_size_centroid_'\n",
    "\n",
    "logbarrier_size_centroid = 'logbarrier_size_centroid_'\n",
    "\n",
    "penalty_size_centroid = 'penalty_size_centroid_'\n",
    "\n",
    "list_methods = [full_sup, cggd_size_centroid, logbarrier_size_centroid, penalty_size_centroid]\n",
    "\n",
    "# The following seeds were used for initializing the neural network\n",
    "seeds_list = [50, 60, 70, 80]\n",
    "\n",
    "# Directory where the postprocessed results should be stored\n",
    "directory_postprocessed_results = './results/toy_postprocess/'\n",
    "\n",
    "if not os.path.isdir(directory_postprocessed_results):\n",
    "    os.makedirs(directory_postprocessed_results)\n",
    "    \n",
    "directory_postprocessed_results_10 = './results/toy_10_postprocess/'\n",
    "\n",
    "if not os.path.isdir(directory_postprocessed_results_10):\n",
    "    os.makedirs(directory_postprocessed_results_10)\n",
    "    \n",
    "directory_postprocessed_results_50 = './results/toy_50_postprocess/'\n",
    "\n",
    "if not os.path.isdir(directory_postprocessed_results_50):\n",
    "    os.makedirs(directory_postprocessed_results_50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1913e-dca4-44fc-bbde-d13b1eb22448",
   "metadata": {},
   "source": [
    "### full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed6639-31b7-4cba-b610-46da33f41b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "# list metrics is the training dice loss, the validation dice loss, the train satisfaction ratio and the validation satisfaction ratio\n",
    "list_metrics = ['tra_dice', 'val_dice', 'tra_sat_ratio', 'val_sat_ratio']\n",
    "\n",
    "# before this can be done, the satisfaction ratio should be recomputed for each epoch.\n",
    "for method in list_methods:\n",
    "    compute_satisfaction_ratio_toy(directory_results=directory_results, method=method, seeds_list=seeds_list, epochs=epochs)\n",
    "\n",
    "for method in list_methods:\n",
    "    compute_mean_max_min_std_method(directory_results=directory_results, method=method, seeds_list=seeds_list, metrics=list_metrics, directory_postprocessed_results=directory_postprocessed_results, epochs=epochs)\n",
    "    \n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results, method=cggd_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results, method=penalty_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results, method=logbarrier_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results, method=full_sup, seeds_list=seeds_list)\n",
    "convert_best_epoch_txt(directory_results=directory_results, methods=list_methods, seeds_list=seeds_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b5719-0491-48b7-8b41-844063f0827a",
   "metadata": {},
   "source": [
    "### 50% of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f6c62-9308-4761-8523-0fcb974c962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "# list metrics is the training dice loss, the validation dice loss, the train satisfaction ratio and the validation satisfaction ratio\n",
    "list_metrics = ['tra_dice', 'val_dice', 'tra_sat_ratio', 'val_sat_ratio']\n",
    "\n",
    "# before this can be done, the satisfaction ratio should be recomputed for each epoch.\n",
    "for method in list_methods:\n",
    "    compute_satisfaction_ratio_toy(directory_results=directory_results_50, method=method, seeds_list=seeds_list, epochs=epochs)\n",
    "\n",
    "for method in list_methods:\n",
    "    compute_mean_max_min_std_method(directory_results=directory_results_50, method=method, seeds_list=seeds_list, metrics=list_metrics, directory_postprocessed_results=directory_postprocessed_results_50, epochs=epochs)\n",
    "    \n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_50, method=cggd_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_50, method=penalty_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_50, method=logbarrier_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_50, method=full_sup, seeds_list=seeds_list)\n",
    "convert_best_epoch_txt(directory_results=directory_results_50, methods=list_methods, seeds_list=seeds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7949125-7be5-4f99-bf8e-d7ab45fda907",
   "metadata": {},
   "source": [
    "### 10% of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004be81-3d71-4275-aefe-b717ca6c4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "# list metrics is the training dice loss, the validation dice loss, the train satisfaction ratio and the validation satisfaction ratio\n",
    "list_metrics = ['tra_dice', 'val_dice', 'tra_sat_ratio', 'val_sat_ratio']\n",
    "\n",
    "# before this can be done, the satisfaction ratio should be recomputed for each epoch.\n",
    "for method in list_methods:\n",
    "    compute_satisfaction_ratio_toy(directory_results=directory_results_10, method=method, seeds_list=seeds_list, epochs=epochs)\n",
    "\n",
    "for method in list_methods:\n",
    "    compute_mean_max_min_std_method(directory_results=directory_results_10, method=method, seeds_list=seeds_list, metrics=list_metrics, directory_postprocessed_results=directory_postprocessed_results_10, epochs=epochs)\n",
    "    \n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_10, method=cggd_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_10, method=penalty_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_10, method=logbarrier_size_centroid, seeds_list=seeds_list)\n",
    "compute_best_epoch_cggd_toy(directory_results=directory_results_10, method=full_sup, seeds_list=seeds_list)\n",
    "convert_best_epoch_txt(directory_results=directory_results_10, methods=list_methods, seeds_list=seeds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d02570-c15f-4fdd-8939-7fa8fd05b339",
   "metadata": {},
   "source": [
    "# Show mean and standard deviation of best epoch\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184dd5e0-cb00-465d-9e1f-63c91e1f0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory results data set\n",
    "directory_results = './results/toy/'\n",
    "directory_results_10 = './results/toy_10/'\n",
    "directory_results_50 = './results/toy_50/'\n",
    "\n",
    "# The following methods are tested\n",
    "full_sup = 'fs_'\n",
    "\n",
    "cggd_size_centroid = 'cggd_size_centroid_'\n",
    "\n",
    "logbarrier_size_centroid = 'logbarrier_size_centroid_'\n",
    "\n",
    "penalty_size_centroid = 'penalty_size_centroid_'\n",
    "\n",
    "list_methods = [full_sup, cggd_size_centroid, logbarrier_size_centroid, penalty_size_centroid]\n",
    "\n",
    "# The following seeds were used for initializing the neural network\n",
    "seeds_list = [50, 60, 70, 80]\n",
    "\n",
    "# Directory where the postprocessed results should be stored\n",
    "directory_postprocessed_results = './results/toy_postprocess/'\n",
    "\n",
    "if not os.path.isdir(directory_postprocessed_results):\n",
    "    os.makedirs(directory_postprocessed_results)\n",
    "    \n",
    "directory_postprocessed_results_10 = './results/toy_10_postprocess/'\n",
    "\n",
    "if not os.path.isdir(directory_postprocessed_results_10):\n",
    "    os.makedirs(directory_postprocessed_results_10)\n",
    "    \n",
    "directory_postprocessed_results_50 = './results/toy_50_postprocess/'\n",
    "\n",
    "if not os.path.isdir(directory_postprocessed_results_50):\n",
    "    os.makedirs(directory_postprocessed_results_50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84709ca1-f026-4a19-a062-5e2edaa1fdd8",
   "metadata": {},
   "source": [
    "### full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7990ba1-d2ba-4d8c-b0a8-132ae7abcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "list_metrics = ['tra_dice', 'val_dice', 'tra_sat_ratio', 'val_sat_ratio']\n",
    "\n",
    "df_mean_std = make_dataframe_mean_std(directory_results=directory_results, directory_postprocessed_results=directory_postprocessed_results, methods=list_methods, metrics=list_metrics, seeds_list=seeds_list, epochs=epochs, custom_epoch_base=custom_epoch_base)\n",
    "\n",
    "df_mean_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6b42c-a25c-4b1b-b8b4-2e325e99e95c",
   "metadata": {},
   "source": [
    "### 50% of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af334bb7-88dc-4a75-a902-4843cf022c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "list_metrics = ['tra_dice', 'val_dice', 'tra_sat_ratio', 'val_sat_ratio']\n",
    "\n",
    "df_mean_std_50 = make_dataframe_mean_std(directory_results=directory_results_50, directory_postprocessed_results=directory_postprocessed_results_50, methods=list_methods, metrics=list_metrics, seeds_list=seeds_list, epochs=epochs, custom_epoch_base=custom_epoch_base)\n",
    "\n",
    "df_mean_std_50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77633ec3-6397-41e1-a78f-5b5ff5101be4",
   "metadata": {},
   "source": [
    "### 10% of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11517c7f-bd77-46fb-b593-285fca56265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "list_metrics = ['tra_dice', 'val_dice', 'tra_sat_ratio', 'val_sat_ratio']\n",
    "\n",
    "df_mean_std_10 = make_dataframe_mean_std(directory_results=directory_results_10, directory_postprocessed_results=directory_postprocessed_results_10, methods=list_methods, metrics=list_metrics, seeds_list=seeds_list, epochs=epochs, custom_epoch_base=custom_epoch_base)\n",
    "\n",
    "df_mean_std_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b61395-19eb-48c0-ba07-d04bab09001e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe3054-602c-412e-b9c9-56787adfa0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be87ea3-053f-445d-9906-6031a2fa13c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation_cggd_kernel",
   "language": "python",
   "name": "segmentation_cggd_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
